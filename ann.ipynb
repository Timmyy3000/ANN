{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import  tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Import dataset\n",
    "dataset = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent Variable\n",
    "x = dataset.iloc[:, 3: -1].values\n",
    "\n",
    "#Independent Variable\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        0        1       2   3   4        5  6  7  8        9\n0     619   France  Female  42   2        0  1  1  1   101349\n1     608    Spain  Female  41   1  83807.9  1  0  1   112543\n2     502   France  Female  42   8   159661  3  1  0   113932\n3     699   France  Female  39   1        0  2  0  0  93826.6\n4     850    Spain  Female  43   2   125511  1  1  1  79084.1\n...   ...      ...     ...  ..  ..      ... .. .. ..      ...\n9995  771   France    Male  39   5        0  2  1  0  96270.6\n9996  516   France    Male  35  10  57369.6  1  1  1   101700\n9997  709   France  Female  36   7        0  1  0  1  42085.6\n9998  772  Germany    Male  42   3  75075.3  2  1  0  92888.5\n9999  792   France  Female  28   4   130143  1  1  0  38190.8\n\n[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print (pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding Independent Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        0        1  2   3   4        5  6  7  8        9\n0     619   France  0  42   2        0  1  1  1   101349\n1     608    Spain  0  41   1  83807.9  1  0  1   112543\n2     502   France  0  42   8   159661  3  1  0   113932\n3     699   France  0  39   1        0  2  0  0  93826.6\n4     850    Spain  0  43   2   125511  1  1  1  79084.1\n...   ...      ... ..  ..  ..      ... .. .. ..      ...\n9995  771   France  1  39   5        0  2  1  0  96270.6\n9996  516   France  1  35  10  57369.6  1  1  1   101700\n9997  709   France  0  36   7        0  1  0  1  42085.6\n9998  772  Germany  1  42   3  75075.3  2  1  0  92888.5\n9999  792   France  0  28   4   130143  1  1  0  38190.8\n\n[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "x[:,2] = le.fit_transform(x[:,2])\n",
    "\n",
    "#Print x as a dataframe\n",
    "print(pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot Encoding of Geography Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1])], remainder=\"passthrough\")\n",
    "\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     0  1  2    3  4   5   6        7  8  9  10       11\n0     1  0  0  619  0  42   2        0  1  1  1   101349\n1     0  0  1  608  0  41   1  83807.9  1  0  1   112543\n2     1  0  0  502  0  42   8   159661  3  1  0   113932\n3     1  0  0  699  0  39   1        0  2  0  0  93826.6\n4     0  0  1  850  0  43   2   125511  1  1  1  79084.1\n...  .. .. ..  ... ..  ..  ..      ... .. .. ..      ...\n9995  1  0  0  771  1  39   5        0  2  1  0  96270.6\n9996  1  0  0  516  1  35  10  57369.6  1  1  1   101700\n9997  1  0  0  709  0  36   7        0  1  0  1  42085.6\n9998  0  1  0  772  1  42   3  75075.3  2  1  0  92888.5\n9999  1  0  0  792  0  28   4   130143  1  1  0  38190.8\n\n[10000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliiting Data Into Train and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size  = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature sclaing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            0         1         2         3         4         5         6   \\\n0    -1.014607 -0.569844  1.743090  0.169582 -1.091687 -0.464608  0.006661   \n1    -1.014607  1.754865 -0.573694 -2.304559  0.916013  0.301026 -1.377440   \n2     0.985604 -0.569844 -0.573694 -1.191196 -1.091687 -0.943129 -1.031415   \n3    -1.014607 -0.569844  1.743090  0.035566  0.916013  0.109617  0.006661   \n4    -1.014607 -0.569844  1.743090  2.056114 -1.091687  1.736588  1.044737   \n...        ...       ...       ...       ...       ...       ...       ...   \n7995 -1.014607  1.754865 -0.573694 -0.582970 -1.091687 -0.656016 -0.339364   \n7996 -1.014607 -0.569844  1.743090  1.478815 -1.091687 -1.613058 -0.339364   \n7997  0.985604 -0.569844 -0.573694  0.901515  0.916013 -0.368904  0.006661   \n7998 -1.014607 -0.569844  1.743090 -0.624205 -1.091687 -0.081791  1.390762   \n7999 -1.014607  1.754865 -0.573694 -0.284011 -1.091687  0.875251 -1.377440   \n\n            7         8         9         10        11  \n0    -1.215717  0.809503  0.642595 -1.032270  1.106432  \n1    -0.006312 -0.921591  0.642595  0.968738 -0.748664  \n2     0.579935 -0.921591  0.642595 -1.032270  1.485335  \n3     0.473128 -0.921591  0.642595 -1.032270  1.276528  \n4     0.810193  0.809503  0.642595  0.968738  0.558378  \n...        ...       ...       ...       ...       ...  \n7995  0.703104  0.809503  0.642595  0.968738  1.091330  \n7996  0.613060 -0.921591  0.642595  0.968738  0.131760  \n7997  1.361474  0.809503  0.642595 -1.032270  1.412320  \n7998 -1.215717  0.809503  0.642595  0.968738  0.844321  \n7999  0.511364 -0.921591  0.642595 -1.032270  0.324725  \n\n[8000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the ANN"
   ]
  },
  {
   "source": [
    "# Initialize sequential ann\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "ann = Sequential()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input layer and hidden layer\n",
    "\n",
    "ann.add(Dense(units = 6, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add second hidden layer\n",
    "\n",
    "ann.add(Dense(units = 6, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add output layer\n",
    "\n",
    "ann.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "source": [
    "## Training The ANN\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Compiling the Ann\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "#### Training the ANN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 5s 574us/sample - loss: 0.5862 - accuracy: 0.7080\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 3s 414us/sample - loss: 0.4526 - accuracy: 0.7961\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 3s 431us/sample - loss: 0.4273 - accuracy: 0.8031\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 0.4184 - accuracy: 0.8117\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.4072 - accuracy: 0.8179\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 126us/sample - loss: 0.3872 - accuracy: 0.8290\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3657 - accuracy: 0.8472\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.3556 - accuracy: 0.8519\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.3521 - accuracy: 0.8537\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 176us/sample - loss: 0.3497 - accuracy: 0.8566\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 6s 713us/sample - loss: 0.3476 - accuracy: 0.8565\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.3460 - accuracy: 0.8561\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 129us/sample - loss: 0.3453 - accuracy: 0.8574\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 136us/sample - loss: 0.3446 - accuracy: 0.8600\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 129us/sample - loss: 0.3432 - accuracy: 0.8581\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.3423 - accuracy: 0.8585\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 129us/sample - loss: 0.3423 - accuracy: 0.8594\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 161us/sample - loss: 0.3414 - accuracy: 0.8601\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 5s 625us/sample - loss: 0.3402 - accuracy: 0.8606\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 205us/sample - loss: 0.3397 - accuracy: 0.8581\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 128us/sample - loss: 0.3389 - accuracy: 0.8629\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 140us/sample - loss: 0.3387 - accuracy: 0.8609\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 135us/sample - loss: 0.3380 - accuracy: 0.8608\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.3383 - accuracy: 0.8605\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 5s 614us/sample - loss: 0.3378 - accuracy: 0.8616\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 4s 460us/sample - loss: 0.3378 - accuracy: 0.8601\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 135us/sample - loss: 0.3372 - accuracy: 0.8605\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 0.3366 - accuracy: 0.8590\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 139us/sample - loss: 0.3366 - accuracy: 0.8616\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.3359 - accuracy: 0.8618\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 285us/sample - loss: 0.3358 - accuracy: 0.8620\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 5s 612us/sample - loss: 0.3358 - accuracy: 0.8620\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 0.3361 - accuracy: 0.8611\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 0.3356 - accuracy: 0.8611\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 127us/sample - loss: 0.3355 - accuracy: 0.8615\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 128us/sample - loss: 0.3358 - accuracy: 0.8611\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.3356 - accuracy: 0.8627\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 3s 319us/sample - loss: 0.3352 - accuracy: 0.8610\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 4s 545us/sample - loss: 0.3350 - accuracy: 0.8620\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.3350 - accuracy: 0.8610\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.3352 - accuracy: 0.8616\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.3346 - accuracy: 0.8614\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.3352 - accuracy: 0.8631\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.3350 - accuracy: 0.8630\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3343 - accuracy: 0.8648\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 0.3349 - accuracy: 0.8622\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 4s 495us/sample - loss: 0.3340 - accuracy: 0.8635\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 3s 322us/sample - loss: 0.3346 - accuracy: 0.8622\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.3341 - accuracy: 0.8594\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 112us/sample - loss: 0.3346 - accuracy: 0.8626\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.3346 - accuracy: 0.8601\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.3343 - accuracy: 0.8624\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 123us/sample - loss: 0.3339 - accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.3347 - accuracy: 0.8624\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.3336 - accuracy: 0.8633\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 114us/sample - loss: 0.3341 - accuracy: 0.8621\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 5s 600us/sample - loss: 0.3338 - accuracy: 0.8621\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 3s 437us/sample - loss: 0.3340 - accuracy: 0.8624\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 130us/sample - loss: 0.3334 - accuracy: 0.8622\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.3337 - accuracy: 0.8626\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.3342 - accuracy: 0.8594\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 127us/sample - loss: 0.3336 - accuracy: 0.8610\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 0.3333 - accuracy: 0.8615\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s 207us/sample - loss: 0.3326 - accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 5s 592us/sample - loss: 0.3336 - accuracy: 0.8639\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 277us/sample - loss: 0.3332 - accuracy: 0.8619\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.3328 - accuracy: 0.8640\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3326 - accuracy: 0.8634\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.3339 - accuracy: 0.8637\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 0.3333 - accuracy: 0.8626\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.3326 - accuracy: 0.8639\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.3329 - accuracy: 0.8627\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.3324 - accuracy: 0.8636\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.3328 - accuracy: 0.8645\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 266us/sample - loss: 0.3323 - accuracy: 0.8639\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 4s 444us/sample - loss: 0.3325 - accuracy: 0.8621\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 169us/sample - loss: 0.3323 - accuracy: 0.8636\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.3323 - accuracy: 0.8596\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.3325 - accuracy: 0.8621\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.3322 - accuracy: 0.8648\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 109us/sample - loss: 0.3319 - accuracy: 0.8621\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.3319 - accuracy: 0.8633\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.3327 - accuracy: 0.8641\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.3321 - accuracy: 0.8627\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.3319 - accuracy: 0.8635\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 3s 404us/sample - loss: 0.3318 - accuracy: 0.8635\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 5s 590us/sample - loss: 0.3319 - accuracy: 0.8626\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.3318 - accuracy: 0.8634\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.3317 - accuracy: 0.8649\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.3317 - accuracy: 0.8637\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.3319 - accuracy: 0.8619\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.3310 - accuracy: 0.8622\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.3308 - accuracy: 0.8633\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 97us/sample - loss: 0.3317 - accuracy: 0.8644\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 3s 423us/sample - loss: 0.3316 - accuracy: 0.8619\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 4s 545us/sample - loss: 0.3314 - accuracy: 0.8644\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 135us/sample - loss: 0.3317 - accuracy: 0.8631\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.3312 - accuracy: 0.8621\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.3312 - accuracy: 0.8641\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 116us/sample - loss: 0.3313 - accuracy: 0.8634\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e9517450b8>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "ann.fit(x_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "source": [
    "## Making Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]])) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 188us/sample - loss: 0.2450 - accuracy: 0.8620\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.3327579075098038, 0.862]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "ann.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3613jvsc74a57bd0005fd61b403ca84a45cc259c31144f5d9e05c700f61a6b3e04c5151a6b4691b5",
   "display_name": "Python 3.6.13 64-bit ('ai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}